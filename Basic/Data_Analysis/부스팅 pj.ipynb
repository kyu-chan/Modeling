{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 가중치, ks와 앤더슨달링의 차이정도?\n",
    "## 수학적인 내용은 추가적인 논문을 학습할 필요가 있음\n",
    "## 발전시키는 모델이지 ----> 베이지안적 개념을 도입해 다른 방향으로 더 공부해볼 필요도?\n",
    "## XGBOOST\n",
    "## 파라미터... learning_rate : 얼마나 빠르게 학습할지, 가중치를 얼마나 높일지..\n",
    "## n_estimator : 가중치 업데이트를 몇번이나 할건지로 생각할 수 있지.. 많으면 오버피팅되니까 적절한 정도를 찾아야겠지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(r'C:\\Users\\pc\\Documents\\data')\n",
    "data = pd.read_csv(\"bank-additional-full.csv\", sep=';')\n",
    "## yes, no를 숫자로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y']=data['y'].replace({'yes': 1, 'no' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "41183    1\n",
       "41184    0\n",
       "41185    0\n",
       "41186    1\n",
       "41187    0\n",
       "Name: y, Length: 41188, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.get_dummies(data, columns=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome'])\n",
    "\n",
    "data['id']= range(len(data))\n",
    "\n",
    "len(data)\n",
    "\n",
    "\n",
    "train = data.sample(30000, replace=False, random_state=2021).reset_index().drop(['index'],axis=1)\n",
    "test = data.loc[ ~data['id'].isin(train['id'])].reset_index().drop(['index'],axis=1)\n",
    "\n",
    "\n",
    "input_var=['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
    "       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed',\n",
    "       'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
    "       'marital_divorced', 'marital_married', 'marital_single',\n",
    "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
    "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
    "       'education_professional.course', 'education_university.degree',\n",
    "       'education_unknown', 'default_no', 'default_unknown', 'default_yes',\n",
    "       'housing_no', 'housing_unknown', 'housing_yes', 'loan_no',\n",
    "       'loan_unknown', 'loan_yes', 'contact_cellular', 'contact_telephone',\n",
    "       'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
    "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "       'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu',\n",
    "       'day_of_week_tue', 'day_of_week_wed', 'poutcome_failure',\n",
    "       'poutcome_nonexistent', 'poutcome_success']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "## XGBOOST 설치\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators = 300, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "29995    0\n",
       "29996    1\n",
       "29997    0\n",
       "29998    0\n",
       "29999    0\n",
       "Name: y, Length: 30000, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=300, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(train[input_var],train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = xgb.predict(test[input_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133893457275652"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test['pred']==test['y']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9143725420092956\n",
      "[23:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9139256346085091\n",
      "[23:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9133893457275652\n",
      "[23:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9122273864855202\n",
      "[23:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9137468716481945\n",
      "[23:05:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9121380050053629\n",
      "[23:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9120486235252055\n",
      "[23:06:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.911601716124419\n",
      "[23:06:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9118698605648909\n"
     ]
    }
   ],
   "source": [
    "for n in [100,200,300,400,500,600,700,800,900]:\n",
    "    xgb = XGBClassifier(n_estimators = n , learning_rate=0.1)\n",
    "\n",
    "    xgb.fit(train[input_var],train['y'])\n",
    "\n",
    "    prediction = xgb.predict(test[input_var])\n",
    "\n",
    "    test['pred'] = prediction\n",
    "\n",
    "    print((test['pred']==test['y']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 결론을 어떻게 해석할래??\n",
    "## 모델의 해석이 필요한 이유, 그리고 모델이란 구체적으로 어떻게 말할 수 있는지..\n",
    "## blackbox를 어떻게...\n",
    "## 특히나 금융데이터 분석의 경우 해석을 못하면 어떻게.. 치명적일 수 도 있는건데..\n",
    "## 도메인특성마다 어느정도로 보수적인지, 그 해석이 얼마나 필요할지, 다양하게 생각해볼 필요가 있다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##변수중요도!! 굉장히 기본적이고 고전적이지만 여기부터 알아보자  -> 트리형 모델에서 보통 쓴다.\n",
    "## input중 어떤것이 target에 가장 영향을 미쳤나?? 교호작용이 있다면??\n",
    "## 그 변수가 얼마나 쓰이냐?, 복잡도를 얼마나 감소시켜주냐? 두가지를 모두 계산\n",
    "## 랜덤포레스트나 xgboost는 각각의 tree에서 변수중요도를 계산한후 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.415464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.039246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>poutcome_success</td>\n",
       "      <td>0.033078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.031224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.028194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>education_illiterate</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>default_yes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>contact_telephone</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>loan_unknown</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>poutcome_nonexistent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var       imp\n",
       "9            nr.employed  0.415464\n",
       "1               duration  0.039246\n",
       "62      poutcome_success  0.033078\n",
       "7          cons.conf.idx  0.031224\n",
       "5           emp.var.rate  0.028194\n",
       "..                   ...       ...\n",
       "30  education_illiterate  0.002969\n",
       "36           default_yes  0.000000\n",
       "44     contact_telephone  0.000000\n",
       "41          loan_unknown  0.000000\n",
       "61  poutcome_nonexistent  0.000000\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = xgb.feature_importances_  ##클수록 중요\n",
    "\n",
    "imp_df =pd.DataFrame({ 'var':input_var ,\n",
    "             'imp':feature_imp})\n",
    "\n",
    "## sorting\n",
    "imp_df.sort_values(['imp'], ascending=False)\n",
    "##통화 오래했니?? 가 가장 영향이 컸구나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomforest의 변수중요도와\n",
    "## xgboost의 변수중요도가 차이가 있는데\n",
    "# 일반적으로 상위모델의 변수중요도가 더 낫다는게 있다. 따라서 이번 pj같은 경우는 nr.employed를 가장 중요한 변수로 보는게 낫겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
